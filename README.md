# wan2shorts üêïüì±

> Turn text prompts into viral YouTube Shorts ‚Äî fully automated, runs daily.

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Platform](https://img.shields.io/badge/platform-Windows%20%28CUDA%29-lightgrey)

**wan2shorts** is an end-to-end pipeline that takes a JSON storyboard of scene prompts and automatically generates, captions, formats, and uploads YouTube Shorts ‚Äî no manual video editing required.

Powered by [WanGP](https://github.com/deepbeepmeep/Wan2GP) (Wan2.1 14B), FFmpeg, and the YouTube Data API.

---

## üé¨ Live Example

All videos on **[@GoooogleAashaan](https://youtube.com/@GoooogleAashaan)** are generated entirely by this pipeline ‚Äî no stock footage, no manual editing.

---

## How It Works

```
Storyboard JSON
      ‚îÇ
      ‚ñº
WanGP (Wan2.1 14B)          ‚Üê generates each scene as a video clip
      ‚îÇ
      ‚ñº
FFmpeg concat                ‚Üê joins scene clips into one video
      ‚îÇ
      ‚ñº
Caption overlay              ‚Üê adds text captions with FFmpeg drawtext
      ‚îÇ
      ‚ñº
Portrait conversion          ‚Üê converts 832√ó480 landscape ‚Üí 1080√ó1920 (9:16)
(blurred background)           with blurred background fill
      ‚îÇ
      ‚ñº
YouTube upload               ‚Üê uploads as public Short via YouTube API
```

---

## ‚ú® Features

- **Text-to-video**: Write scene prompts ‚Üí get a complete Short
- **Auto-captions**: Scene text overlaid on video
- **Portrait conversion**: Automatic landscape ‚Üí 1080√ó1920 Shorts format
- **YouTube API integration**: Uploads directly, sets title/description/tags/privacy
- **Daily automation**: Run on a schedule, report results
- **Low-VRAM mode**: Works on 6GB GPUs with env overrides
- **Batch generation**: Generate and upload multiple videos in one run

---

## Requirements

- **OS**: Windows 10/11 (WanGP requires Windows + CUDA)
- **GPU**: NVIDIA with 8GB+ VRAM (6GB works ‚Äî see [Low-VRAM Mode](#low-vram-mode))
- **Python**: 3.10+
- **FFmpeg**: Installed and in `PATH`
- **WanGP**: Installed separately ‚Äî see [WanGP setup](https://github.com/deepbeepmeep/Wan2GP)
- **YouTube Data API v3** credentials (OAuth2)

---

## Installation

```bash
git clone https://github.com/lijinlar/ai-shorts-lab
cd ai-shorts-lab
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

---

## Setup

### 1. Install WanGP

Follow the [WanGP installation guide](https://github.com/deepbeepmeep/Wan2GP). By default, wan2shorts expects WanGP at:

```
C:\Users\<you>\.openclaw\workspace\Wan2GP\
```

To change this, edit `WAN2GP_DIR` in `scripts/generate_shorts_wangp.py`.

### 2. YouTube Authentication

```bash
python scripts/youtube_auth.py --channel main
```

This opens a browser to authorize via OAuth2. The token is saved to `out/youtube_token.json`.

For multiple channels, use `--channel dogs`, `--channel aitools`, etc. ‚Äî each gets its own token file.

---

## Storyboard Format

Storyboards are JSON files that define what to generate. See `storyboards/example.json` for a full example.

```json
{
  "default": {
    "sceneSeconds": 3,
    "fps": 24,
    "width": 480,
    "height": 832,
    "backend": "wangp",
    "upscale4k": false
  },
  "videos": [
    {
      "title": "Dog Reunites With Owner After 18 Months üò≠ #shorts",
      "description": "Emotional dog reunion. #shorts #dog",
      "scenes": [
        {
          "prompt": "Extreme close-up: a golden retriever's nose twitches near a front door, amber light, static camera. Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus"
        },
        {
          "prompt": "Medium wide: soldier drops duffel bag at door, retriever freezes with ears perked, tail wagging, warm hallway light, slow push-in. Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus"
        }
      ]
    }
  ]
}
```

### Prompt tips for best results

Each scene prompt should include:
1. **Shot type** ‚Äî `Extreme close-up`, `Medium wide`, `Low angle`, etc.
2. **Subject detail** ‚Äî breed, color, expression, body language
3. **Action** ‚Äî precise movement with speed/direction
4. **Environment** ‚Äî lighting, surfaces, time of day
5. **Camera motion** ‚Äî `static`, `slow push-in`, `tracking shot`, etc.
6. **Quality suffix** ‚Äî always end with: `Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus`

---

## Running

### Generate and upload from a storyboard

```bash
python scripts/full_daily_pipeline.py --storyboard storyboards/example.json
```

### Upload as unlisted (for testing)

```bash
python scripts/full_daily_pipeline.py --storyboard storyboards/example.json --privacy unlisted
```

### Generate a single video directly

```bash
python scripts/generate_shorts_wangp.py storyboards/example.json out/my_video.mp4
```

### Daily automation

Set up a scheduled task (Windows Task Scheduler) or cron to run:

```bash
python scripts/full_daily_pipeline.py --storyboard storyboards/todays_storyboard.json
```

---

## Low-VRAM Mode

If you have a 6GB GPU or hit CUDA out-of-memory errors, set these environment variables before running:

```bash
set WANGP_MODEL_TYPE=t2v_1.3B
set WANGP_STEPS=10
set WANGP_CFG=4.0
```

Or in PowerShell:

```powershell
$env:WANGP_MODEL_TYPE = "t2v_1.3B"
$env:WANGP_STEPS = "10"
```

This switches to the 1.3B parameter model and reduces inference steps ‚Äî much lower VRAM usage, slightly lower quality.

---

## Project Structure

```
ai-shorts-lab/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ full_daily_pipeline.py          # Main entry point ‚Äî runs the full pipeline
‚îÇ   ‚îú‚îÄ‚îÄ generate_shorts_wangp.py        # Core: storyboard ‚Üí video via WanGP
‚îÇ   ‚îú‚îÄ‚îÄ batch_generate_upload_series_wangp.py  # Batch multi-video generation
‚îÇ   ‚îú‚îÄ‚îÄ add_captions.py                 # FFmpeg caption overlay
‚îÇ   ‚îú‚îÄ‚îÄ concat_scenes.py                # FFmpeg scene concatenation
‚îÇ   ‚îú‚îÄ‚îÄ convert_to_shorts_format.py     # Landscape ‚Üí 1080√ó1920 portrait
‚îÇ   ‚îú‚îÄ‚îÄ youtube_upload.py               # YouTube API upload
‚îÇ   ‚îú‚îÄ‚îÄ youtube_auth.py                 # OAuth2 token setup
‚îÇ   ‚îú‚îÄ‚îÄ youtube_analytics_report.py     # Performance analytics
‚îÇ   ‚îú‚îÄ‚îÄ combine_and_upload.py           # Combine scenes + upload in one step
‚îÇ   ‚îú‚îÄ‚îÄ wangp_generate_scene.py         # Low-level WanGP scene generator
‚îÇ   ‚îú‚îÄ‚îÄ auto_process_wangp.py           # WanGP queue auto-processor
‚îÇ   ‚îú‚îÄ‚îÄ daily_youtube_automation.py     # Alternate daily automation entry
‚îÇ   ‚îî‚îÄ‚îÄ archive/                        # Experimental/superseded scripts
‚îú‚îÄ‚îÄ storyboards/
‚îÇ   ‚îî‚îÄ‚îÄ example.json                    # Example storyboard ‚Äî start here
‚îú‚îÄ‚îÄ out/                                # Generated videos and tokens (gitignored)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Known Quirks

- **WanGP always outputs 832√ó480** ‚Äî the model generates landscape video regardless of the `width`/`height` params in the storyboard. The pipeline automatically converts to 1080√ó1920 portrait using a blurred background fill. This is expected behavior.

- **No audio by default** ‚Äî WanGP generates silent video. Background music support is not yet built in. Add audio via FFmpeg separately if needed.

- **GPU memory spikes** ‚Äî each scene is generated independently to avoid OOM. Large frame counts (>81 frames) can still crash on 8GB GPUs.

- **YouTube Shorts classification** ‚Äî YouTube automatically classifies videos as Shorts if they are ‚â§60 seconds and in portrait (9:16) format. The `#shorts` tag in the title/description helps but is not strictly required.

---

## License

MIT ‚Äî free to use, modify, and build on.

---

## Credits

- Video generation: [WanGP / Wan2.1](https://github.com/deepbeepmeep/Wan2GP) by deepbeepmeep
- YouTube API: Google YouTube Data API v3
- Video processing: FFmpeg
