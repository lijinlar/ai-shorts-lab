# ai-shorts-lab ðŸ•ðŸ“±

> Turn text prompts into viral YouTube Shorts â€” fully automated, runs daily.

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Platform](https://img.shields.io/badge/platform-Windows%20%28CUDA%29-lightgrey)

**ai-shorts-lab** is an end-to-end pipeline that takes a JSON storyboard of scene prompts and automatically generates, captions, formats, and uploads YouTube Shorts â€” no manual video editing required.

Powered by [WanGP](https://github.com/deepbeepmeep/Wan2GP) (Wan2.1 14B), FFmpeg, and the YouTube Data API v3.

---

## ðŸŽ¬ Live Example

All videos on **[@GoooogleAashaan](https://youtube.com/@GoooogleAashaan)** are generated entirely by this pipeline â€” no stock footage, no manual editing.

---

## How It Works

```
Storyboard JSON
      â”‚
      â–¼
WanGP (Wan2.1 14B)          â† generates each scene as a video clip
      â”‚
      â–¼
FFmpeg concat                â† joins scene clips into one video
      â”‚
      â–¼
Caption overlay              â† adds text captions with FFmpeg drawtext
      â”‚
      â–¼
Portrait conversion          â† converts 832Ã—480 landscape â†’ 1080Ã—1920 (9:16)
(blurred background)           with blurred background fill
      â”‚
      â–¼
YouTube upload               â† uploads as public Short via YouTube API
```

---

## âœ¨ Features

- **Text-to-video**: Write scene prompts â†’ get a complete Short
- **Auto-captions**: Scene text overlaid on video
- **Portrait conversion**: Automatic landscape â†’ 1080Ã—1920 Shorts format
- **YouTube API integration**: Uploads directly, sets title/description/tags/privacy
- **Daily automation**: Run on a schedule, report results
- **Low-VRAM mode**: Works on 6GB GPUs with env overrides
- **Batch generation**: Generate and upload multiple videos in one run

---

## Requirements

- **OS**: Windows 10/11 (WanGP requires Windows + CUDA)
- **GPU**: NVIDIA with 8GB+ VRAM (6GB works â€” see [Low-VRAM Mode](#low-vram-mode))
- **Python**: 3.10+
- **FFmpeg**: Installed and in `PATH` â€” [download here](https://ffmpeg.org/download.html)
- **WanGP**: Installed separately â€” see [WanGP Setup](#wangp-setup) below
- **YouTube Data API v3** credentials â€” see [YouTube Auth](#youtube-auth)

---

## Installation

```bash
git clone https://github.com/lijinlar/ai-shorts-lab
cd ai-shorts-lab
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

---

## Configuration

All user-specific paths live in `config.yaml`. Copy the example and fill in your paths:

```bash
cp config.example.yaml config.yaml
```

Then edit `config.yaml`:

```yaml
# Path to your local WanGP installation
wangp:
  dir: "C:/path/to/Wan2GP"

# Path to your YouTube OAuth2 client credentials JSON
# Download from: Google Cloud Console â†’ APIs & Services â†’ Credentials â†’ OAuth 2.0 Client ID
youtube:
  oauth_credentials: "C:/path/to/youtube.oauth.json"
```

> `config.yaml` is gitignored â€” never committed. `config.example.yaml` is the safe template.

---

## WanGP Setup

WanGP is the video generation backend. It runs locally on your GPU using the Wan2.1 model.

### 1. Clone and install WanGP

```bash
git clone https://github.com/deepbeepmeep/Wan2GP
cd Wan2GP
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Download the Wan2.1 model

WanGP will prompt you to download the model on first run, or you can download manually:

- **Wan2.1-T2V-14B** (recommended, ~30GB) â€” best quality, needs 16GB VRAM or 8GB with CPU offload
- **Wan2.1-T2V-1.3B** (lightweight, ~5GB) â€” runs on 6GB VRAM, faster but lower quality

Follow the [WanGP model download guide](https://github.com/deepbeepmeep/Wan2GP#model-download) for exact steps.

### 3. Configure the path in ai-shorts-lab

By default, ai-shorts-lab expects WanGP at:

```
C:\Users\<YourUsername>\.wan2gp\Wan2GP\
```

To use a different path, edit `WAN2GP_DIR` at the top of `scripts/generate_shorts_wangp.py`:

```python
WAN2GP_DIR = Path(r"C:\path\to\your\Wan2GP")
```

### 4. Verify WanGP works

Test that WanGP generates a video before running the full pipeline:

```bash
cd Wan2GP
venv\Scripts\activate
python wgp.py
```

This opens the WanGP UI. Generate a test clip to confirm your GPU setup is working.

---

## YouTube Auth

### 1. Create a Google Cloud project

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project
3. Enable the **YouTube Data API v3**
4. Go to **APIs & Services â†’ Credentials**
5. Create **OAuth 2.0 Client ID** â†’ Application type: **Desktop app**
6. Download the JSON file â€” save it anywhere on your machine (e.g. `C:/secrets/youtube.oauth.json`)
7. Set the path in your `config.yaml`:
   ```yaml
   youtube:
     oauth_credentials: "C:/secrets/youtube.oauth.json"
   ```

### 2. Authenticate

```bash
python scripts/youtube_auth.py --channel main
```

This opens a browser window to authorize your YouTube account. The token is saved to `out/youtube_token.json` and reused for future runs.

For multiple channels:

```bash
python scripts/youtube_auth.py --channel dogs    # saves out/youtube_token_dogs.json
python scripts/youtube_auth.py --channel main    # saves out/youtube_token.json
```

---

## Storyboard Format

Storyboards are JSON files that define what to generate. See `storyboards/example.json` for a full example.

```json
{
  "default": {
    "sceneSeconds": 3,
    "fps": 24,
    "width": 480,
    "height": 832,
    "backend": "wangp",
    "upscale4k": false
  },
  "videos": [
    {
      "title": "Dog Reunites With Owner After 18 Months ðŸ˜­ #shorts",
      "description": "Emotional dog reunion. #shorts #dog",
      "scenes": [
        {
          "prompt": "Extreme close-up: a golden retriever's nose twitches near a front door, amber light, static camera. Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus"
        },
        {
          "prompt": "Medium wide: soldier drops duffel bag at door, retriever freezes with ears perked, tail wagging, warm hallway light, slow push-in. Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus"
        }
      ]
    }
  ]
}
```

### Prompt tips for best results

Each scene prompt should include:
1. **Shot type** â€” `Extreme close-up`, `Medium wide`, `Low angle`, etc.
2. **Subject detail** â€” breed, color, expression, body language
3. **Action** â€” precise movement with speed/direction
4. **Environment** â€” lighting, surfaces, time of day
5. **Camera motion** â€” `static`, `slow push-in`, `tracking shot`, etc.
6. **Quality suffix** â€” always end with: `Ultra-realistic, photorealistic, cinematic 4K, shallow depth of field, smooth motion, sharp focus`

---

## Running

### Generate and upload from a storyboard

```bash
python scripts/full_daily_pipeline.py --storyboard storyboards/example.json
```

### Upload as unlisted (for testing)

```bash
python scripts/full_daily_pipeline.py --storyboard storyboards/example.json --privacy unlisted
```

### Generate a single video directly

```bash
python scripts/generate_shorts_wangp.py storyboards/example.json out/my_video.mp4
```

### Daily automation

Set up a **Windows Task Scheduler** task or any cron-compatible scheduler to run daily:

```bash
cd C:\path\to\ai-shorts-lab
.venv\Scripts\activate
python scripts/full_daily_pipeline.py --storyboard storyboards/todays_storyboard.json
```

---

## Low-VRAM Mode

If you have a 6GB GPU or hit CUDA out-of-memory errors, set these environment variables before running:

**PowerShell:**
```powershell
$env:WANGP_MODEL_TYPE = "t2v_1.3B"
$env:WANGP_STEPS = "10"
$env:WANGP_CFG = "4.0"
```

**Command Prompt:**
```cmd
set WANGP_MODEL_TYPE=t2v_1.3B
set WANGP_STEPS=10
```

This switches to the 1.3B parameter model and reduces inference steps â€” much lower VRAM usage, slightly lower quality.

---

## Project Structure

```
ai-shorts-lab/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ full_daily_pipeline.py          # Main entry point â€” runs the full pipeline
â”‚   â”œâ”€â”€ generate_shorts_wangp.py        # Core: storyboard â†’ video via WanGP
â”‚   â”œâ”€â”€ batch_generate_upload_series_wangp.py  # Batch multi-video generation
â”‚   â”œâ”€â”€ add_captions.py                 # FFmpeg caption overlay
â”‚   â”œâ”€â”€ concat_scenes.py                # FFmpeg scene concatenation
â”‚   â”œâ”€â”€ convert_to_shorts_format.py     # Landscape â†’ 1080Ã—1920 portrait
â”‚   â”œâ”€â”€ youtube_upload.py               # YouTube API upload
â”‚   â”œâ”€â”€ youtube_auth.py                 # OAuth2 token setup
â”‚   â”œâ”€â”€ youtube_analytics_report.py     # Performance analytics
â”‚   â”œâ”€â”€ combine_and_upload.py           # Combine scenes + upload in one step
â”‚   â”œâ”€â”€ wangp_generate_scene.py         # Low-level WanGP scene generator
â”‚   â”œâ”€â”€ auto_process_wangp.py           # WanGP queue auto-processor
â”‚   â”œâ”€â”€ daily_youtube_automation.py     # Alternate daily automation entry
â”‚   â””â”€â”€ archive/                        # Experimental/superseded scripts
â”œâ”€â”€ storyboards/
â”‚   â””â”€â”€ example.json                    # Example storyboard â€” start here
â”œâ”€â”€ out/                                # Generated videos and tokens (gitignored)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Known Quirks

- **WanGP always outputs 832Ã—480** â€” the model generates landscape video regardless of the `width`/`height` params in the storyboard. The pipeline automatically converts to 1080Ã—1920 portrait using a blurred background fill. This is expected behavior.

- **No audio by default** â€” WanGP generates silent video. Add background music separately via FFmpeg if needed.

- **GPU memory spikes** â€” each scene is generated independently to avoid OOM. Large frame counts (>81 frames) can still crash on 8GB GPUs.

- **YouTube Shorts classification** â€” YouTube automatically classifies videos as Shorts if they are â‰¤60 seconds and in portrait (9:16) format. Adding `#shorts` to the title helps.

---

## License

MIT â€” free to use, modify, and build on.

---

## Credits

- Video generation: [WanGP / Wan2.1](https://github.com/deepbeepmeep/Wan2GP) by deepbeepmeep
- YouTube API: Google YouTube Data API v3
- Video processing: FFmpeg
